{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec8443d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\anaconda3\\envs\\Shayekh_20230126\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from art.estimators.classification import SklearnClassifier\n",
    "from art.attacks.evasion import ZooAttack\n",
    "from art.utils import load_mnist\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import platform\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "186852ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\Desktop\\Research lab\\Covid_AI_Research_Lab\\Machine_Learning\n"
     ]
    }
   ],
   "source": [
    "cd \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88a3407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\Desktop\\Research lab\\Covid_AI_Research_Lab\n"
     ]
    }
   ],
   "source": [
    "cd \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8bae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the pre_processed data\n",
    "os_type = platform.system()\n",
    "if os_type.startswith(\"Darwin\"):\n",
    "    data = pd.read_excel(r\"dataset/processed_data/main/merged_scored_dataset1.xlsx\")\n",
    "else: \n",
    "    data = pd.read_excel(r\"dataset\\processed_data\\main\\merged_scored_dataset1.xlsx\")\n",
    "#Droping the target col\n",
    "feature_value_temp = data.drop(\"Laboratory confirmed, since the beginning of the pandemic Hospitalized\", axis=1)\n",
    "#Droping the Distric col as it is string and will be assigned value by clustering\n",
    "features = feature_value_temp.drop(\"District\",axis=1)\n",
    "features = features.drop(\"Unnamed: 0\",axis=1)\n",
    "features = features.drop(\"Laboratory confirmed, since the beginning of the pandemic TOTAL\",axis=1)\n",
    "features = features.drop(\"Laboratory confirmed, since the beginning of the pandemic RecoveredA\",axis=1)\n",
    "features = features.drop(\"Laboratory confirmed, since the beginning of the pandemic Deceased\",axis=1)\n",
    "\n",
    "\n",
    "data['flag'] = 3  # Initialize the 'flag' column with 0\n",
    "data.loc[data['Laboratory confirmed, since the beginning of the pandemic Hospitalized'] <= 449, 'flag'] = 2\n",
    "data.loc[data['Laboratory confirmed, since the beginning of the pandemic Hospitalized'] <= 290, 'flag'] = 1\n",
    "\n",
    "target_col = data[\"flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1814089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target_col, test_size=0.3, random_state=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "198893ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ZOO:   0%|          | 6/11690 [00:06<3:20:36,  1.03s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=50, random_state= 22)\n",
    "model.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Create ART classifier for scikit-learn RandomForestClassifier\n",
    "art_classifier = SklearnClassifier(model=model)\n",
    "\n",
    "# Create ART Zeroth Order Optimization attack\n",
    "zoo = ZooAttack(classifier=art_classifier, confidence=0.0, targeted=False, learning_rate=1e-1, max_iter=20,\n",
    "                binary_search_steps=10, initial_const=1e-3, abort_early=True, use_resize=False, \n",
    "                use_importance=False, nb_parallel=1, batch_size=1, variable_h=0.2)\n",
    "\n",
    " # Generate adversarial samples with ART Zeroth Order Optimization attack\n",
    "x_train_adv = zoo.generate(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efe6bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_adv = np.load('adversarial_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82416bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ZOO: 100%|██████████| 5010/5010 [49:22<00:00,  1.69it/s]   \n"
     ]
    }
   ],
   "source": [
    "x_test_adv = zoo.generate(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ac55ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_test_adv.npy', x_test_adv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da3aa4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Training Score: 0.9985\n",
      "Adversarial Training Score: 0.9739\n",
      "Normal Test Score: 0.7715\n",
      "Adversarial Test Score: 0.7527\n"
     ]
    }
   ],
   "source": [
    "score = model.score(X_train, y_train)\n",
    "print(\"Normal Training Score: %.4f\" % score)\n",
    "\n",
    "score = model.score(x_train_adv, y_train)\n",
    "print(\"Adversarial Training Score: %.4f\" % score)\n",
    "\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"Normal Test Score: %.4f\" % score)\n",
    "\n",
    "score = model.score(x_test_adv, y_test)\n",
    "print(\"Adversarial Test Score: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b0315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a mapping between column names and numbers\n",
    "# def convert_to_numbers(df):\n",
    "#     column_mapping = {col: i for i, col in enumerate(df.columns)}\n",
    "#     df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "# convert_to_numbers(X_train)\n",
    "# convert_to_numbers(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87983fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "92febad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 23.37818172449867\n",
      "Mean Squared Error: 546.5393807436836\n",
      "R2 Score: 0.9957503364591642\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1783ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcb06439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "Recall: 0.77\n",
      "Precision: 0.76\n",
      "F1 Score: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "#model = RandomForestClassifier(n_estimators=50, random_state= 22)\n",
    "#model.fit(X_train,y_train)\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, recall, precision, and F1 score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred,average='weighted')\n",
    "precision = precision_score(y_test, y_pred,average='weighted')\n",
    "f1 = f1_score(y_test, y_pred,average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d40ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2b48f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d1509f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #AttributeInferenceBlackBox Attacking\n",
    "# import numpy as np\n",
    "# from art.attacks.inference.attribute_inference import AttributeInferenceBlackBox\n",
    "\n",
    "# attack_train_ratio = 0.5\n",
    "# attack_train_size = int(len(X_train) * attack_train_ratio)\n",
    "# attack_x_train = X_train[:attack_train_size].values\n",
    "# attack_y_train = y_train[:attack_train_size]\n",
    "# attack_x_test = X_train[attack_train_size:].values\n",
    "# attack_y_test = y_train[attack_train_size:]\n",
    "\n",
    "# attack_feature = 2  # sex\n",
    "\n",
    "# # get original model's predictions\n",
    "# attack_x_test_predictions = np.array([np.argmax(arr) for arr in art_regressor.predict(attack_x_test)]).reshape(-1,1)\n",
    "# # only attacked feature\n",
    "# attack_x_test_feature = attack_x_test[:, attack_feature].copy().reshape(-1, 1)\n",
    "# # training data without attacked feature\n",
    "# attack_x_test = np.delete(attack_x_test, attack_feature, 1)\n",
    "\n",
    "# bb_attack = AttributeInferenceBlackBox(art_regressor, attack_feature=attack_feature, is_continuous = True)\n",
    "\n",
    "# # train attack model\n",
    "# bb_attack.fit(attack_x_train)\n",
    "\n",
    "\n",
    "# # get inferred values\n",
    "# values = [6084,  35802.5  ]\n",
    "# inferred_train_bb = bb_attack.infer(attack_x_test, pred=attack_x_test_predictions)\n",
    "# # check accuracy\n",
    "# train_acc = np.sum(inferred_train_bb == np.around(attack_x_test_feature, decimals=8).reshape(1,-1)) / len(inferred_train_bb)\n",
    "# print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eebf2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b02625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
